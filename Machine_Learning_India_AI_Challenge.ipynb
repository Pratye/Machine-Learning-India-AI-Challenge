{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Machine Learning India AI Challenge",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pratye/Machine-Learning-India-AI-Challenge/blob/main/Machine_Learning_India_AI_Challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_u413EmuEqQ",
        "outputId": "e750779e-970d-47e1-e455-e3c049f12791"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFLKd41LEwKr"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8Fwu2X5kqUW"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JF9-R3AeE66D"
      },
      "source": [
        "## Loading and Augmentation of Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWKg8ZXgkqUf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "8599a623-de0c-485c-bf41-3ac3eb4cc1c4"
      },
      "source": [
        "df=pd.read_csv(\"/content/drive/MyDrive/machine_learning_india_ai_challenge-dataset/TRAIN.csv\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Index</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2.245295</td>\n",
              "      <td>-1.160960</td>\n",
              "      <td>-1.966682</td>\n",
              "      <td>-1.430190</td>\n",
              "      <td>-0.607246</td>\n",
              "      <td>-1.508696</td>\n",
              "      <td>-0.074415</td>\n",
              "      <td>-0.655096</td>\n",
              "      <td>-1.970141</td>\n",
              "      <td>1.607283</td>\n",
              "      <td>-0.780267</td>\n",
              "      <td>-0.294928</td>\n",
              "      <td>1.236719</td>\n",
              "      <td>-0.135565</td>\n",
              "      <td>-0.832677</td>\n",
              "      <td>-1.400205</td>\n",
              "      <td>0.807960</td>\n",
              "      <td>-0.670317</td>\n",
              "      <td>-0.044106</td>\n",
              "      <td>-0.292081</td>\n",
              "      <td>0.010490</td>\n",
              "      <td>0.521714</td>\n",
              "      <td>-0.064971</td>\n",
              "      <td>0.048849</td>\n",
              "      <td>0.383290</td>\n",
              "      <td>0.103970</td>\n",
              "      <td>-0.047350</td>\n",
              "      <td>-0.064800</td>\n",
              "      <td>74.75</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1.278609</td>\n",
              "      <td>0.102574</td>\n",
              "      <td>0.512079</td>\n",
              "      <td>0.003930</td>\n",
              "      <td>-0.723474</td>\n",
              "      <td>-1.334105</td>\n",
              "      <td>0.029958</td>\n",
              "      <td>-0.296595</td>\n",
              "      <td>0.128119</td>\n",
              "      <td>-0.209865</td>\n",
              "      <td>0.188511</td>\n",
              "      <td>0.674525</td>\n",
              "      <td>0.712608</td>\n",
              "      <td>0.122319</td>\n",
              "      <td>1.038024</td>\n",
              "      <td>0.128638</td>\n",
              "      <td>-0.222614</td>\n",
              "      <td>-0.687546</td>\n",
              "      <td>-0.056504</td>\n",
              "      <td>-0.040015</td>\n",
              "      <td>-0.081470</td>\n",
              "      <td>-0.182506</td>\n",
              "      <td>0.078986</td>\n",
              "      <td>0.789993</td>\n",
              "      <td>0.219794</td>\n",
              "      <td>0.938359</td>\n",
              "      <td>-0.078720</td>\n",
              "      <td>0.008119</td>\n",
              "      <td>1.38</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1.466457</td>\n",
              "      <td>0.026088</td>\n",
              "      <td>-0.499298</td>\n",
              "      <td>-0.674372</td>\n",
              "      <td>-0.144883</td>\n",
              "      <td>-1.178075</td>\n",
              "      <td>0.058089</td>\n",
              "      <td>-0.420145</td>\n",
              "      <td>-1.359651</td>\n",
              "      <td>0.210249</td>\n",
              "      <td>-0.033777</td>\n",
              "      <td>-0.001594</td>\n",
              "      <td>1.767471</td>\n",
              "      <td>-1.212943</td>\n",
              "      <td>0.427684</td>\n",
              "      <td>1.252714</td>\n",
              "      <td>0.843412</td>\n",
              "      <td>-1.534474</td>\n",
              "      <td>0.830734</td>\n",
              "      <td>0.207653</td>\n",
              "      <td>-0.234087</td>\n",
              "      <td>-0.710542</td>\n",
              "      <td>-0.001242</td>\n",
              "      <td>-0.174713</td>\n",
              "      <td>0.533719</td>\n",
              "      <td>-0.454779</td>\n",
              "      <td>0.001524</td>\n",
              "      <td>0.030935</td>\n",
              "      <td>10.95</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>-0.922137</td>\n",
              "      <td>-0.371579</td>\n",
              "      <td>2.132018</td>\n",
              "      <td>-0.796997</td>\n",
              "      <td>0.324175</td>\n",
              "      <td>-1.162006</td>\n",
              "      <td>0.277208</td>\n",
              "      <td>-0.249586</td>\n",
              "      <td>-0.775648</td>\n",
              "      <td>-0.061757</td>\n",
              "      <td>-0.959725</td>\n",
              "      <td>0.408746</td>\n",
              "      <td>0.597641</td>\n",
              "      <td>-0.802430</td>\n",
              "      <td>-1.889520</td>\n",
              "      <td>-1.607785</td>\n",
              "      <td>-0.401475</td>\n",
              "      <td>0.729773</td>\n",
              "      <td>-2.445693</td>\n",
              "      <td>-0.461062</td>\n",
              "      <td>-0.302654</td>\n",
              "      <td>-0.246899</td>\n",
              "      <td>-0.045745</td>\n",
              "      <td>0.677110</td>\n",
              "      <td>0.016109</td>\n",
              "      <td>-0.734220</td>\n",
              "      <td>-0.034480</td>\n",
              "      <td>-0.064786</td>\n",
              "      <td>8.04</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>-1.166525</td>\n",
              "      <td>0.255439</td>\n",
              "      <td>2.108464</td>\n",
              "      <td>0.135019</td>\n",
              "      <td>-0.072979</td>\n",
              "      <td>0.910821</td>\n",
              "      <td>0.755918</td>\n",
              "      <td>0.355528</td>\n",
              "      <td>-0.422820</td>\n",
              "      <td>-0.842826</td>\n",
              "      <td>0.663538</td>\n",
              "      <td>0.624657</td>\n",
              "      <td>0.107262</td>\n",
              "      <td>-0.073654</td>\n",
              "      <td>-0.305506</td>\n",
              "      <td>0.618642</td>\n",
              "      <td>-0.952529</td>\n",
              "      <td>0.757618</td>\n",
              "      <td>-0.375461</td>\n",
              "      <td>0.353355</td>\n",
              "      <td>0.136470</td>\n",
              "      <td>0.017496</td>\n",
              "      <td>0.121017</td>\n",
              "      <td>0.636266</td>\n",
              "      <td>0.492943</td>\n",
              "      <td>-0.750242</td>\n",
              "      <td>0.029124</td>\n",
              "      <td>0.091303</td>\n",
              "      <td>175.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Index        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0      0  2.245295 -1.160960 -1.966682  ... -0.047350 -0.064800   74.75      0\n",
              "1      1  1.278609  0.102574  0.512079  ... -0.078720  0.008119    1.38      0\n",
              "2      2  1.466457  0.026088 -0.499298  ...  0.001524  0.030935   10.95      0\n",
              "3      3 -0.922137 -0.371579  2.132018  ... -0.034480 -0.064786    8.04      0\n",
              "4      4 -1.166525  0.255439  2.108464  ...  0.029124  0.091303  175.00      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIeXJ9CIkqUg"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkNIFyBpkqUh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "977e4552-55f9-4435-d5bd-54b20477744e"
      },
      "source": [
        "from sklearn.utils import resample\n",
        "df_majority = df[df.Class==0]\n",
        "df_minority = df[df.Class!=0]\n",
        "df_minority\n",
        " \n",
        "#Downsample majority class\n",
        "df_majority_downsampled = resample(df_majority,replace=False,n_samples=500,random_state=123) \n",
        " \n",
        "dataset1 = pd.concat([df_majority_downsampled, df_minority])\n",
        " \n",
        "# Display new class counts\n",
        "dataset1.Class.value_counts()\n",
        "dataset1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Index</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5557</th>\n",
              "      <td>5557</td>\n",
              "      <td>-0.286506</td>\n",
              "      <td>1.483877</td>\n",
              "      <td>1.296656</td>\n",
              "      <td>1.830624</td>\n",
              "      <td>0.804772</td>\n",
              "      <td>-0.620905</td>\n",
              "      <td>1.537253</td>\n",
              "      <td>-0.533306</td>\n",
              "      <td>-1.574283</td>\n",
              "      <td>0.585061</td>\n",
              "      <td>-0.391437</td>\n",
              "      <td>0.085668</td>\n",
              "      <td>1.013337</td>\n",
              "      <td>-0.067326</td>\n",
              "      <td>-0.091619</td>\n",
              "      <td>0.096048</td>\n",
              "      <td>-0.640788</td>\n",
              "      <td>-0.510616</td>\n",
              "      <td>-0.750035</td>\n",
              "      <td>0.020316</td>\n",
              "      <td>0.035584</td>\n",
              "      <td>0.220838</td>\n",
              "      <td>-0.294050</td>\n",
              "      <td>0.421327</td>\n",
              "      <td>0.292934</td>\n",
              "      <td>-0.017196</td>\n",
              "      <td>-0.300206</td>\n",
              "      <td>-0.210138</td>\n",
              "      <td>20.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189143</th>\n",
              "      <td>189143</td>\n",
              "      <td>0.027315</td>\n",
              "      <td>-2.962887</td>\n",
              "      <td>0.323169</td>\n",
              "      <td>-0.062928</td>\n",
              "      <td>-1.823663</td>\n",
              "      <td>0.883502</td>\n",
              "      <td>-0.427193</td>\n",
              "      <td>0.174294</td>\n",
              "      <td>-0.220772</td>\n",
              "      <td>0.197776</td>\n",
              "      <td>0.867747</td>\n",
              "      <td>0.588848</td>\n",
              "      <td>0.372375</td>\n",
              "      <td>-0.614239</td>\n",
              "      <td>-1.051076</td>\n",
              "      <td>0.812886</td>\n",
              "      <td>0.603264</td>\n",
              "      <td>-1.286998</td>\n",
              "      <td>0.762201</td>\n",
              "      <td>1.373300</td>\n",
              "      <td>0.455065</td>\n",
              "      <td>0.028891</td>\n",
              "      <td>-0.591603</td>\n",
              "      <td>-0.244121</td>\n",
              "      <td>0.095391</td>\n",
              "      <td>-0.281050</td>\n",
              "      <td>-0.054412</td>\n",
              "      <td>0.121573</td>\n",
              "      <td>657.55</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>217166</th>\n",
              "      <td>217166</td>\n",
              "      <td>1.161457</td>\n",
              "      <td>0.342126</td>\n",
              "      <td>0.596969</td>\n",
              "      <td>1.137035</td>\n",
              "      <td>-0.289921</td>\n",
              "      <td>-0.597790</td>\n",
              "      <td>0.093898</td>\n",
              "      <td>-0.114521</td>\n",
              "      <td>-0.085083</td>\n",
              "      <td>-0.071066</td>\n",
              "      <td>0.275224</td>\n",
              "      <td>0.815874</td>\n",
              "      <td>0.715484</td>\n",
              "      <td>0.230024</td>\n",
              "      <td>1.166685</td>\n",
              "      <td>-0.249527</td>\n",
              "      <td>-0.120944</td>\n",
              "      <td>-0.814322</td>\n",
              "      <td>-0.860259</td>\n",
              "      <td>-0.128026</td>\n",
              "      <td>0.005647</td>\n",
              "      <td>0.107395</td>\n",
              "      <td>0.038325</td>\n",
              "      <td>0.402180</td>\n",
              "      <td>0.449769</td>\n",
              "      <td>-0.431766</td>\n",
              "      <td>0.043762</td>\n",
              "      <td>0.027593</td>\n",
              "      <td>7.19</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44582</th>\n",
              "      <td>44582</td>\n",
              "      <td>1.935320</td>\n",
              "      <td>-0.571370</td>\n",
              "      <td>-0.875981</td>\n",
              "      <td>-0.098773</td>\n",
              "      <td>0.061064</td>\n",
              "      <td>0.634513</td>\n",
              "      <td>-0.573312</td>\n",
              "      <td>0.165900</td>\n",
              "      <td>0.777935</td>\n",
              "      <td>0.111132</td>\n",
              "      <td>0.048667</td>\n",
              "      <td>1.079360</td>\n",
              "      <td>0.982807</td>\n",
              "      <td>-0.120085</td>\n",
              "      <td>-0.116394</td>\n",
              "      <td>0.953468</td>\n",
              "      <td>-1.217769</td>\n",
              "      <td>0.380287</td>\n",
              "      <td>0.610641</td>\n",
              "      <td>0.046221</td>\n",
              "      <td>-0.199225</td>\n",
              "      <td>-0.619102</td>\n",
              "      <td>0.254756</td>\n",
              "      <td>-0.334198</td>\n",
              "      <td>-0.501719</td>\n",
              "      <td>0.278271</td>\n",
              "      <td>-0.050622</td>\n",
              "      <td>-0.045397</td>\n",
              "      <td>64.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152158</th>\n",
              "      <td>152158</td>\n",
              "      <td>1.119941</td>\n",
              "      <td>-0.216024</td>\n",
              "      <td>1.362047</td>\n",
              "      <td>0.959006</td>\n",
              "      <td>-1.276754</td>\n",
              "      <td>-0.491515</td>\n",
              "      <td>-0.592218</td>\n",
              "      <td>0.046830</td>\n",
              "      <td>0.910009</td>\n",
              "      <td>-0.249010</td>\n",
              "      <td>-0.443562</td>\n",
              "      <td>0.536990</td>\n",
              "      <td>-0.034620</td>\n",
              "      <td>-0.377712</td>\n",
              "      <td>0.180358</td>\n",
              "      <td>0.070765</td>\n",
              "      <td>-0.053027</td>\n",
              "      <td>-0.336049</td>\n",
              "      <td>-0.170090</td>\n",
              "      <td>-0.072864</td>\n",
              "      <td>-0.058449</td>\n",
              "      <td>-0.021478</td>\n",
              "      <td>0.054220</td>\n",
              "      <td>0.747833</td>\n",
              "      <td>0.202373</td>\n",
              "      <td>0.294721</td>\n",
              "      <td>0.013497</td>\n",
              "      <td>0.033920</td>\n",
              "      <td>28.75</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279108</th>\n",
              "      <td>279108</td>\n",
              "      <td>-1.322789</td>\n",
              "      <td>1.552768</td>\n",
              "      <td>-2.276921</td>\n",
              "      <td>2.992117</td>\n",
              "      <td>-1.947064</td>\n",
              "      <td>-0.480288</td>\n",
              "      <td>-1.362388</td>\n",
              "      <td>0.953242</td>\n",
              "      <td>-2.329629</td>\n",
              "      <td>-3.393553</td>\n",
              "      <td>3.128440</td>\n",
              "      <td>-3.570394</td>\n",
              "      <td>-0.595198</td>\n",
              "      <td>-3.988415</td>\n",
              "      <td>0.995906</td>\n",
              "      <td>-2.843785</td>\n",
              "      <td>-4.826246</td>\n",
              "      <td>-0.703883</td>\n",
              "      <td>2.152215</td>\n",
              "      <td>0.988493</td>\n",
              "      <td>0.614969</td>\n",
              "      <td>-0.195200</td>\n",
              "      <td>0.590711</td>\n",
              "      <td>-0.233378</td>\n",
              "      <td>-0.164285</td>\n",
              "      <td>-0.277498</td>\n",
              "      <td>0.428610</td>\n",
              "      <td>0.246394</td>\n",
              "      <td>270.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279194</th>\n",
              "      <td>279194</td>\n",
              "      <td>-18.474868</td>\n",
              "      <td>11.586381</td>\n",
              "      <td>-21.402917</td>\n",
              "      <td>6.038515</td>\n",
              "      <td>-14.451158</td>\n",
              "      <td>-4.146524</td>\n",
              "      <td>-14.856124</td>\n",
              "      <td>12.431140</td>\n",
              "      <td>-4.053353</td>\n",
              "      <td>-9.040396</td>\n",
              "      <td>5.966203</td>\n",
              "      <td>-8.463966</td>\n",
              "      <td>0.078692</td>\n",
              "      <td>-9.092533</td>\n",
              "      <td>0.010822</td>\n",
              "      <td>-7.186376</td>\n",
              "      <td>-13.797475</td>\n",
              "      <td>-4.958494</td>\n",
              "      <td>1.321167</td>\n",
              "      <td>1.577924</td>\n",
              "      <td>1.741136</td>\n",
              "      <td>-1.251138</td>\n",
              "      <td>-0.396219</td>\n",
              "      <td>0.095706</td>\n",
              "      <td>1.322751</td>\n",
              "      <td>-0.217955</td>\n",
              "      <td>1.628793</td>\n",
              "      <td>0.482248</td>\n",
              "      <td>99.99</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279528</th>\n",
              "      <td>279528</td>\n",
              "      <td>0.378275</td>\n",
              "      <td>3.914797</td>\n",
              "      <td>-5.726872</td>\n",
              "      <td>6.094141</td>\n",
              "      <td>1.698875</td>\n",
              "      <td>-2.807314</td>\n",
              "      <td>-0.591118</td>\n",
              "      <td>-0.123496</td>\n",
              "      <td>-2.530713</td>\n",
              "      <td>-5.153095</td>\n",
              "      <td>4.654088</td>\n",
              "      <td>-7.839539</td>\n",
              "      <td>1.371819</td>\n",
              "      <td>-9.634690</td>\n",
              "      <td>-0.739597</td>\n",
              "      <td>-0.663204</td>\n",
              "      <td>0.891935</td>\n",
              "      <td>0.978676</td>\n",
              "      <td>-2.005477</td>\n",
              "      <td>0.440439</td>\n",
              "      <td>0.149896</td>\n",
              "      <td>-0.601967</td>\n",
              "      <td>-0.613724</td>\n",
              "      <td>-0.403114</td>\n",
              "      <td>1.568445</td>\n",
              "      <td>0.521884</td>\n",
              "      <td>0.527938</td>\n",
              "      <td>0.411910</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>280854</th>\n",
              "      <td>280854</td>\n",
              "      <td>-1.201398</td>\n",
              "      <td>4.864535</td>\n",
              "      <td>-8.328823</td>\n",
              "      <td>7.652399</td>\n",
              "      <td>-0.167445</td>\n",
              "      <td>-2.767695</td>\n",
              "      <td>-3.176421</td>\n",
              "      <td>1.623279</td>\n",
              "      <td>-4.367228</td>\n",
              "      <td>-5.533443</td>\n",
              "      <td>4.106405</td>\n",
              "      <td>-6.331825</td>\n",
              "      <td>0.671785</td>\n",
              "      <td>-12.156587</td>\n",
              "      <td>1.020252</td>\n",
              "      <td>-2.110863</td>\n",
              "      <td>-1.558545</td>\n",
              "      <td>0.195992</td>\n",
              "      <td>0.502453</td>\n",
              "      <td>0.597026</td>\n",
              "      <td>0.532320</td>\n",
              "      <td>-0.556913</td>\n",
              "      <td>0.192444</td>\n",
              "      <td>-0.698588</td>\n",
              "      <td>0.025003</td>\n",
              "      <td>0.514968</td>\n",
              "      <td>0.378105</td>\n",
              "      <td>-0.053133</td>\n",
              "      <td>0.77</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282522</th>\n",
              "      <td>282522</td>\n",
              "      <td>-6.677212</td>\n",
              "      <td>5.529299</td>\n",
              "      <td>-7.193275</td>\n",
              "      <td>6.081321</td>\n",
              "      <td>-1.636071</td>\n",
              "      <td>0.500610</td>\n",
              "      <td>-4.640770</td>\n",
              "      <td>-4.339840</td>\n",
              "      <td>-0.950036</td>\n",
              "      <td>0.566680</td>\n",
              "      <td>4.315076</td>\n",
              "      <td>-4.938284</td>\n",
              "      <td>-1.105710</td>\n",
              "      <td>-8.490813</td>\n",
              "      <td>1.003626</td>\n",
              "      <td>-1.949123</td>\n",
              "      <td>-3.093013</td>\n",
              "      <td>0.124087</td>\n",
              "      <td>0.886747</td>\n",
              "      <td>-1.118687</td>\n",
              "      <td>5.563301</td>\n",
              "      <td>-1.608272</td>\n",
              "      <td>0.965322</td>\n",
              "      <td>0.163718</td>\n",
              "      <td>0.047531</td>\n",
              "      <td>0.466165</td>\n",
              "      <td>0.278547</td>\n",
              "      <td>1.471988</td>\n",
              "      <td>105.89</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>940 rows Ã— 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Index         V1         V2  ...       V28  Amount  Class\n",
              "5557      5557  -0.286506   1.483877  ... -0.210138   20.00      0\n",
              "189143  189143   0.027315  -2.962887  ...  0.121573  657.55      0\n",
              "217166  217166   1.161457   0.342126  ...  0.027593    7.19      0\n",
              "44582    44582   1.935320  -0.571370  ... -0.045397   64.00      0\n",
              "152158  152158   1.119941  -0.216024  ...  0.033920   28.75      0\n",
              "...        ...        ...        ...  ...       ...     ...    ...\n",
              "279108  279108  -1.322789   1.552768  ...  0.246394  270.00      1\n",
              "279194  279194 -18.474868  11.586381  ...  0.482248   99.99      1\n",
              "279528  279528   0.378275   3.914797  ...  0.411910    1.00      1\n",
              "280854  280854  -1.201398   4.864535  ... -0.053133    0.77      1\n",
              "282522  282522  -6.677212   5.529299  ...  1.471988  105.89      1\n",
              "\n",
              "[940 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4L5_fWVBkqUh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "6977e468-ab97-4b50-d514-2b3268f53739"
      },
      "source": [
        "inputs=dataset1.drop([\"Index\",\"Class\"],axis=\"columns\")\n",
        "target=dataset1[\"Class\"]\n",
        "inputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5557</th>\n",
              "      <td>-0.286506</td>\n",
              "      <td>1.483877</td>\n",
              "      <td>1.296656</td>\n",
              "      <td>1.830624</td>\n",
              "      <td>0.804772</td>\n",
              "      <td>-0.620905</td>\n",
              "      <td>1.537253</td>\n",
              "      <td>-0.533306</td>\n",
              "      <td>-1.574283</td>\n",
              "      <td>0.585061</td>\n",
              "      <td>-0.391437</td>\n",
              "      <td>0.085668</td>\n",
              "      <td>1.013337</td>\n",
              "      <td>-0.067326</td>\n",
              "      <td>-0.091619</td>\n",
              "      <td>0.096048</td>\n",
              "      <td>-0.640788</td>\n",
              "      <td>-0.510616</td>\n",
              "      <td>-0.750035</td>\n",
              "      <td>0.020316</td>\n",
              "      <td>0.035584</td>\n",
              "      <td>0.220838</td>\n",
              "      <td>-0.294050</td>\n",
              "      <td>0.421327</td>\n",
              "      <td>0.292934</td>\n",
              "      <td>-0.017196</td>\n",
              "      <td>-0.300206</td>\n",
              "      <td>-0.210138</td>\n",
              "      <td>20.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189143</th>\n",
              "      <td>0.027315</td>\n",
              "      <td>-2.962887</td>\n",
              "      <td>0.323169</td>\n",
              "      <td>-0.062928</td>\n",
              "      <td>-1.823663</td>\n",
              "      <td>0.883502</td>\n",
              "      <td>-0.427193</td>\n",
              "      <td>0.174294</td>\n",
              "      <td>-0.220772</td>\n",
              "      <td>0.197776</td>\n",
              "      <td>0.867747</td>\n",
              "      <td>0.588848</td>\n",
              "      <td>0.372375</td>\n",
              "      <td>-0.614239</td>\n",
              "      <td>-1.051076</td>\n",
              "      <td>0.812886</td>\n",
              "      <td>0.603264</td>\n",
              "      <td>-1.286998</td>\n",
              "      <td>0.762201</td>\n",
              "      <td>1.373300</td>\n",
              "      <td>0.455065</td>\n",
              "      <td>0.028891</td>\n",
              "      <td>-0.591603</td>\n",
              "      <td>-0.244121</td>\n",
              "      <td>0.095391</td>\n",
              "      <td>-0.281050</td>\n",
              "      <td>-0.054412</td>\n",
              "      <td>0.121573</td>\n",
              "      <td>657.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>217166</th>\n",
              "      <td>1.161457</td>\n",
              "      <td>0.342126</td>\n",
              "      <td>0.596969</td>\n",
              "      <td>1.137035</td>\n",
              "      <td>-0.289921</td>\n",
              "      <td>-0.597790</td>\n",
              "      <td>0.093898</td>\n",
              "      <td>-0.114521</td>\n",
              "      <td>-0.085083</td>\n",
              "      <td>-0.071066</td>\n",
              "      <td>0.275224</td>\n",
              "      <td>0.815874</td>\n",
              "      <td>0.715484</td>\n",
              "      <td>0.230024</td>\n",
              "      <td>1.166685</td>\n",
              "      <td>-0.249527</td>\n",
              "      <td>-0.120944</td>\n",
              "      <td>-0.814322</td>\n",
              "      <td>-0.860259</td>\n",
              "      <td>-0.128026</td>\n",
              "      <td>0.005647</td>\n",
              "      <td>0.107395</td>\n",
              "      <td>0.038325</td>\n",
              "      <td>0.402180</td>\n",
              "      <td>0.449769</td>\n",
              "      <td>-0.431766</td>\n",
              "      <td>0.043762</td>\n",
              "      <td>0.027593</td>\n",
              "      <td>7.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44582</th>\n",
              "      <td>1.935320</td>\n",
              "      <td>-0.571370</td>\n",
              "      <td>-0.875981</td>\n",
              "      <td>-0.098773</td>\n",
              "      <td>0.061064</td>\n",
              "      <td>0.634513</td>\n",
              "      <td>-0.573312</td>\n",
              "      <td>0.165900</td>\n",
              "      <td>0.777935</td>\n",
              "      <td>0.111132</td>\n",
              "      <td>0.048667</td>\n",
              "      <td>1.079360</td>\n",
              "      <td>0.982807</td>\n",
              "      <td>-0.120085</td>\n",
              "      <td>-0.116394</td>\n",
              "      <td>0.953468</td>\n",
              "      <td>-1.217769</td>\n",
              "      <td>0.380287</td>\n",
              "      <td>0.610641</td>\n",
              "      <td>0.046221</td>\n",
              "      <td>-0.199225</td>\n",
              "      <td>-0.619102</td>\n",
              "      <td>0.254756</td>\n",
              "      <td>-0.334198</td>\n",
              "      <td>-0.501719</td>\n",
              "      <td>0.278271</td>\n",
              "      <td>-0.050622</td>\n",
              "      <td>-0.045397</td>\n",
              "      <td>64.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152158</th>\n",
              "      <td>1.119941</td>\n",
              "      <td>-0.216024</td>\n",
              "      <td>1.362047</td>\n",
              "      <td>0.959006</td>\n",
              "      <td>-1.276754</td>\n",
              "      <td>-0.491515</td>\n",
              "      <td>-0.592218</td>\n",
              "      <td>0.046830</td>\n",
              "      <td>0.910009</td>\n",
              "      <td>-0.249010</td>\n",
              "      <td>-0.443562</td>\n",
              "      <td>0.536990</td>\n",
              "      <td>-0.034620</td>\n",
              "      <td>-0.377712</td>\n",
              "      <td>0.180358</td>\n",
              "      <td>0.070765</td>\n",
              "      <td>-0.053027</td>\n",
              "      <td>-0.336049</td>\n",
              "      <td>-0.170090</td>\n",
              "      <td>-0.072864</td>\n",
              "      <td>-0.058449</td>\n",
              "      <td>-0.021478</td>\n",
              "      <td>0.054220</td>\n",
              "      <td>0.747833</td>\n",
              "      <td>0.202373</td>\n",
              "      <td>0.294721</td>\n",
              "      <td>0.013497</td>\n",
              "      <td>0.033920</td>\n",
              "      <td>28.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279108</th>\n",
              "      <td>-1.322789</td>\n",
              "      <td>1.552768</td>\n",
              "      <td>-2.276921</td>\n",
              "      <td>2.992117</td>\n",
              "      <td>-1.947064</td>\n",
              "      <td>-0.480288</td>\n",
              "      <td>-1.362388</td>\n",
              "      <td>0.953242</td>\n",
              "      <td>-2.329629</td>\n",
              "      <td>-3.393553</td>\n",
              "      <td>3.128440</td>\n",
              "      <td>-3.570394</td>\n",
              "      <td>-0.595198</td>\n",
              "      <td>-3.988415</td>\n",
              "      <td>0.995906</td>\n",
              "      <td>-2.843785</td>\n",
              "      <td>-4.826246</td>\n",
              "      <td>-0.703883</td>\n",
              "      <td>2.152215</td>\n",
              "      <td>0.988493</td>\n",
              "      <td>0.614969</td>\n",
              "      <td>-0.195200</td>\n",
              "      <td>0.590711</td>\n",
              "      <td>-0.233378</td>\n",
              "      <td>-0.164285</td>\n",
              "      <td>-0.277498</td>\n",
              "      <td>0.428610</td>\n",
              "      <td>0.246394</td>\n",
              "      <td>270.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279194</th>\n",
              "      <td>-18.474868</td>\n",
              "      <td>11.586381</td>\n",
              "      <td>-21.402917</td>\n",
              "      <td>6.038515</td>\n",
              "      <td>-14.451158</td>\n",
              "      <td>-4.146524</td>\n",
              "      <td>-14.856124</td>\n",
              "      <td>12.431140</td>\n",
              "      <td>-4.053353</td>\n",
              "      <td>-9.040396</td>\n",
              "      <td>5.966203</td>\n",
              "      <td>-8.463966</td>\n",
              "      <td>0.078692</td>\n",
              "      <td>-9.092533</td>\n",
              "      <td>0.010822</td>\n",
              "      <td>-7.186376</td>\n",
              "      <td>-13.797475</td>\n",
              "      <td>-4.958494</td>\n",
              "      <td>1.321167</td>\n",
              "      <td>1.577924</td>\n",
              "      <td>1.741136</td>\n",
              "      <td>-1.251138</td>\n",
              "      <td>-0.396219</td>\n",
              "      <td>0.095706</td>\n",
              "      <td>1.322751</td>\n",
              "      <td>-0.217955</td>\n",
              "      <td>1.628793</td>\n",
              "      <td>0.482248</td>\n",
              "      <td>99.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279528</th>\n",
              "      <td>0.378275</td>\n",
              "      <td>3.914797</td>\n",
              "      <td>-5.726872</td>\n",
              "      <td>6.094141</td>\n",
              "      <td>1.698875</td>\n",
              "      <td>-2.807314</td>\n",
              "      <td>-0.591118</td>\n",
              "      <td>-0.123496</td>\n",
              "      <td>-2.530713</td>\n",
              "      <td>-5.153095</td>\n",
              "      <td>4.654088</td>\n",
              "      <td>-7.839539</td>\n",
              "      <td>1.371819</td>\n",
              "      <td>-9.634690</td>\n",
              "      <td>-0.739597</td>\n",
              "      <td>-0.663204</td>\n",
              "      <td>0.891935</td>\n",
              "      <td>0.978676</td>\n",
              "      <td>-2.005477</td>\n",
              "      <td>0.440439</td>\n",
              "      <td>0.149896</td>\n",
              "      <td>-0.601967</td>\n",
              "      <td>-0.613724</td>\n",
              "      <td>-0.403114</td>\n",
              "      <td>1.568445</td>\n",
              "      <td>0.521884</td>\n",
              "      <td>0.527938</td>\n",
              "      <td>0.411910</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>280854</th>\n",
              "      <td>-1.201398</td>\n",
              "      <td>4.864535</td>\n",
              "      <td>-8.328823</td>\n",
              "      <td>7.652399</td>\n",
              "      <td>-0.167445</td>\n",
              "      <td>-2.767695</td>\n",
              "      <td>-3.176421</td>\n",
              "      <td>1.623279</td>\n",
              "      <td>-4.367228</td>\n",
              "      <td>-5.533443</td>\n",
              "      <td>4.106405</td>\n",
              "      <td>-6.331825</td>\n",
              "      <td>0.671785</td>\n",
              "      <td>-12.156587</td>\n",
              "      <td>1.020252</td>\n",
              "      <td>-2.110863</td>\n",
              "      <td>-1.558545</td>\n",
              "      <td>0.195992</td>\n",
              "      <td>0.502453</td>\n",
              "      <td>0.597026</td>\n",
              "      <td>0.532320</td>\n",
              "      <td>-0.556913</td>\n",
              "      <td>0.192444</td>\n",
              "      <td>-0.698588</td>\n",
              "      <td>0.025003</td>\n",
              "      <td>0.514968</td>\n",
              "      <td>0.378105</td>\n",
              "      <td>-0.053133</td>\n",
              "      <td>0.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282522</th>\n",
              "      <td>-6.677212</td>\n",
              "      <td>5.529299</td>\n",
              "      <td>-7.193275</td>\n",
              "      <td>6.081321</td>\n",
              "      <td>-1.636071</td>\n",
              "      <td>0.500610</td>\n",
              "      <td>-4.640770</td>\n",
              "      <td>-4.339840</td>\n",
              "      <td>-0.950036</td>\n",
              "      <td>0.566680</td>\n",
              "      <td>4.315076</td>\n",
              "      <td>-4.938284</td>\n",
              "      <td>-1.105710</td>\n",
              "      <td>-8.490813</td>\n",
              "      <td>1.003626</td>\n",
              "      <td>-1.949123</td>\n",
              "      <td>-3.093013</td>\n",
              "      <td>0.124087</td>\n",
              "      <td>0.886747</td>\n",
              "      <td>-1.118687</td>\n",
              "      <td>5.563301</td>\n",
              "      <td>-1.608272</td>\n",
              "      <td>0.965322</td>\n",
              "      <td>0.163718</td>\n",
              "      <td>0.047531</td>\n",
              "      <td>0.466165</td>\n",
              "      <td>0.278547</td>\n",
              "      <td>1.471988</td>\n",
              "      <td>105.89</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>940 rows Ã— 29 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               V1         V2         V3  ...       V27       V28  Amount\n",
              "5557    -0.286506   1.483877   1.296656  ... -0.300206 -0.210138   20.00\n",
              "189143   0.027315  -2.962887   0.323169  ... -0.054412  0.121573  657.55\n",
              "217166   1.161457   0.342126   0.596969  ...  0.043762  0.027593    7.19\n",
              "44582    1.935320  -0.571370  -0.875981  ... -0.050622 -0.045397   64.00\n",
              "152158   1.119941  -0.216024   1.362047  ...  0.013497  0.033920   28.75\n",
              "...           ...        ...        ...  ...       ...       ...     ...\n",
              "279108  -1.322789   1.552768  -2.276921  ...  0.428610  0.246394  270.00\n",
              "279194 -18.474868  11.586381 -21.402917  ...  1.628793  0.482248   99.99\n",
              "279528   0.378275   3.914797  -5.726872  ...  0.527938  0.411910    1.00\n",
              "280854  -1.201398   4.864535  -8.328823  ...  0.378105 -0.053133    0.77\n",
              "282522  -6.677212   5.529299  -7.193275  ...  0.278547  1.471988  105.89\n",
              "\n",
              "[940 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Test Split"
      ],
      "metadata": {
        "id": "Q4ToEMfzYdi3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFzgCW6xkqUh"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(inputs,target,test_size=0.4)\n",
        "dataset=pd.concat([X_train,y_train ], axis=1, sort=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYURzppDkqUi"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler() \n",
        "X_train = scaler.fit_transform(X_train) \n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "_kmVa9_mYj8n"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvcOd7cXKZI5"
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=5)\n",
        "random_state = 17\n",
        "classifiers = []\n",
        "classifiers.append(SVC(random_state=random_state))\n",
        "classifiers.append(DecisionTreeClassifier(random_state=random_state))\n",
        "classifiers.append(AdaBoostClassifier(DecisionTreeClassifier(random_state=random_state),random_state=random_state,learning_rate=0.1))\n",
        "classifiers.append(RandomForestClassifier(random_state=random_state))\n",
        "classifiers.append(ExtraTreesClassifier(random_state=random_state))\n",
        "classifiers.append(GradientBoostingClassifier(random_state=random_state))\n",
        "classifiers.append(MLPClassifier(random_state=random_state))\n",
        "classifiers.append(KNeighborsClassifier())\n",
        "classifiers.append(LogisticRegression(random_state = random_state))\n",
        "classifiers.append(LinearDiscriminantAnalysis())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3bI3DG6KZT5"
      },
      "source": [
        "cv_results = []\n",
        "for classifier in classifiers :\n",
        "    cv_results.append(cross_val_score(classifier, x1_train, y = y1_train, \n",
        "                                      scoring = \"f1\", cv = kfold, n_jobs=-1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUrYC7gxKZeb"
      },
      "source": [
        "cv_means = []\n",
        "cv_std = []\n",
        "for cv_result in cv_results:\n",
        "    cv_means.append(cv_result.mean())\n",
        "    cv_std.append(cv_result.std())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAIAXZO7KZnq"
      },
      "source": [
        "cv_res = pd.DataFrame({\"CrossValMeans\":cv_means,\"CrossValerrors\": cv_std,\"Algorithm\":[\"SVC\",\"DecisionTree\",\"AdaBoost\",\n",
        "\"RandomForest\",\"ExtraTrees\",\"GradientBoosting\",\"MultipleLayerPerceptron\",\"KNeighboors\",\"LogisticRegression\",\"LinearDiscriminantAnalysis\"]})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "Q58MvWWHKZwT",
        "outputId": "eaa04f9a-9155-4436-954e-169d7a5ed33d"
      },
      "source": [
        "import seaborn as sns\n",
        "g = sns.barplot(\"CrossValMeans\",\"Algorithm\",data = cv_res, palette=\"Set3\",orient = \"h\",**{'xerr':cv_std})\n",
        "g.set_xlabel(\"Mean Accuracy\")\n",
        "g = g.set_title(\"Cross validation scores\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQj6kXUMkqUj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b189cd0-713d-4f6f-f230-8f5a09327024"
      },
      "source": [
        "model1.score(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9335106382978723"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 334
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Applying Gradient Boost Classifier"
      ],
      "metadata": {
        "id": "Ygvh1tzoY43r"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAf_x9ZPkqUi"
      },
      "source": [
        "model1=GradientBoostingClassifier(n_estimators=200000,max_depth=4,learning_rate=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxK1zXYUkqUj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3cf2242-f36a-4413-d8d7-5d16713c82a9"
      },
      "source": [
        "model1.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
              "                           learning_rate=0.01, loss='deviance', max_depth=4,\n",
              "                           max_features=None, max_leaf_nodes=None,\n",
              "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                           min_samples_leaf=1, min_samples_split=2,\n",
              "                           min_weight_fraction_leaf=0.0, n_estimators=200000,\n",
              "                           n_iter_no_change=None, presort='deprecated',\n",
              "                           random_state=None, subsample=1.0, tol=0.0001,\n",
              "                           validation_fraction=0.1, verbose=0,\n",
              "                           warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 333
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnKxgee2kqUk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2bd2174-e7ad-4edb-aa8e-dffed23ab40f"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "params = {\"n_estimators\": [100,200,300,500],\n",
        "          \"max_depth\": [None],\n",
        "          \"learning_rate\": [1, 0.1, 0.01, 0.001]\n",
        "}\n",
        "model2=GradientBoostingClassifier()\n",
        "\n",
        "gsas = GridSearchCV(model2, params, cv = 5, verbose = 1,scoring=\"accuracy\", n_jobs= 4)\n",
        "gsas.fit(x1_train,y1_train)\n",
        "gsas.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   13.5s\n",
            "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   58.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9149178255372945"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Applying Extra Trees Classifier"
      ],
      "metadata": {
        "id": "drC_GQTLY_TH"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZJ7KHIhLDDe",
        "outputId": "f43b2181-33a0-4764-d847-7ce8cbf780bf"
      },
      "source": [
        "ExtC = ExtraTreesClassifier()\n",
        "\n",
        "\n",
        "## Search grid for optimal parameters\n",
        "ex_param_grid = {\"max_depth\": [None],\n",
        "              \"max_features\": [1, 3, 10],\n",
        "              \"min_samples_split\": [2, 3, 10],\n",
        "              \"min_samples_leaf\": [1, 3, 10],\n",
        "              \"bootstrap\": [False],\n",
        "              \"n_estimators\" :[100,300],\n",
        "              \"criterion\": [\"gini\"]}\n",
        "\n",
        "\n",
        "gsExtC = GridSearchCV(ExtC,param_grid = ex_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n",
        "\n",
        "gsExtC.fit(x1_train,y = y1_train)\n",
        "\n",
        "ExtC_best = gsExtC.best_estimator_\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    9.4s\n",
            "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   38.1s\n",
            "[Parallel(n_jobs=4)]: Done 270 out of 270 | elapsed:   55.0s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WN8-spCKLovv",
        "outputId": "388813c9-e067-4931-9ca1-818a5f8c5597"
      },
      "source": [
        "gsExtC.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9432522123893806"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Applying Logistic Regression"
      ],
      "metadata": {
        "id": "lRZH8nJ2ZDNp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEPMrkpYNC5E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34c4542b-8d94-4ea3-c1b2-186e823ad11b"
      },
      "source": [
        "clf = LogisticRegression()\n",
        "#model3 = clf.fit(x1_train, y1_train)\n",
        "#model3.score(x_test,y_test)\n",
        "\n",
        "clf_param_grid = {\"warm_start\": [True],\n",
        "                  \"solver\": ['saga'],\n",
        "                  ##\"l1_ratio\": [],\n",
        "                  #\"dual\": [True],\n",
        "                  \"class_weight\": ['balanced'],\n",
        "                  \"random_state\" : [False],\n",
        "                  \n",
        "     }\n",
        "\n",
        "gsclf = GridSearchCV(clf,param_grid = clf_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= -1, verbose = 1)\n",
        "gsclf.fit(x1_train,y = y1_train)\n",
        "clf_best = gsclf.best_estimator_\n",
        "gsclf.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.4s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9450537294563844"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 337
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Model Accuracy achieved by Logistic Regression"
      ],
      "metadata": {
        "id": "YNqz-yzcZHW3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPw77hfCjbHJ",
        "outputId": "5cd6f86b-81cf-4fe2-a59d-e5be7c10838c"
      },
      "source": [
        "#clf = LogisticRegression()\n",
        "model3 = LogisticRegression(solver='newton-cg',max_iter=100).fit(x1_train, y1_train)\n",
        "model3.score(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9441489361702128"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 336
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting on New Data"
      ],
      "metadata": {
        "id": "12PDfoTRZM8b"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NaXx8NQkqUl"
      },
      "source": [
        "new_test_data = pd.read_csv(\"/content/drive/MyDrive/machine_learning_india_ai_challenge-dataset/TEST.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7vjSR5hkqUm"
      },
      "source": [
        "test_new=new_test_data.drop([\"Index\"],axis=\"columns\")\n",
        "target = model2.predict(test_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDlfIzKvkqUm"
      },
      "source": [
        "res = pd.DataFrame(target)  \n",
        "res.index = test_new.index \n",
        "res.columns = [\"prediction\"]\n",
        "res.to_csv(\"prediction_results.csv\", index = False)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeBZkHswkqUn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}